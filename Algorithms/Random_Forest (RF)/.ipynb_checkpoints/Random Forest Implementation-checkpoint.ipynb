{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    " \n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "forest = RandomForestRegressor()\n",
    "fit= rf.fit(boston.data[:300], boston.target[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00851156  0.00099265  0.0037045   0.00164665  0.00829101  0.03331663\n",
      "  0.00462351  0.00424436  0.00337528  0.00819881  0.00746823  0.00664567\n",
      "  0.02963939]\n"
     ]
    }
   ],
   "source": [
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 5 (0.795153)\n",
      "2. feature 12 (0.118318)\n",
      "3. feature 0 (0.017974)\n",
      "4. feature 9 (0.012883)\n",
      "5. feature 6 (0.010618)\n",
      "6. feature 10 (0.010365)\n",
      "7. feature 7 (0.009954)\n",
      "8. feature 4 (0.008119)\n",
      "9. feature 11 (0.007336)\n",
      "10. feature 2 (0.004478)\n",
      "11. feature 8 (0.002487)\n",
      "12. feature 3 (0.001476)\n",
      "13. feature 1 (0.000841)\n"
     ]
    }
   ],
   "source": [
    "#feature importance for boston\n",
    "forest.fit(boston.data[:300], boston.target[:300])\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(boston.data[:300].shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(boston.data.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(boston.data.shape[1]), indices)\n",
    "plt.xlim([-1, boston.data.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 0 prediction: [ 30.28]\n",
      "Instance 1 prediction: [ 22.64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ernestt/venv/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/ernestt/venv/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "instances = boston.data[[300, 309]]\n",
    "print \"Instance 0 prediction:\", rf.predict(instances[0])\n",
    "print \"Instance 1 prediction:\", rf.predict(instances[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print boston.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction, biases, contributions = ti.predict(rf, instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 0\n",
      "Bias (trainset mean) 25.2699666667\n",
      "Feature contributions:\n",
      "RM 2.91\n",
      "LSTAT 2.16\n",
      "DIS -0.56\n",
      "TAX -0.55\n",
      "NOX 0.37\n",
      "PTRATIO 0.27\n",
      "INDUS 0.24\n",
      "AGE 0.19\n",
      "CRIM -0.15\n",
      "RAD 0.1\n",
      "ZN 0.07\n",
      "B -0.03\n",
      "CHAS 0.0\n",
      "--------------------\n",
      "Instance 1\n",
      "Bias (trainset mean) 25.2699666667\n",
      "Feature contributions:\n",
      "RM -5.3\n",
      "LSTAT 2.61\n",
      "CRIM 0.52\n",
      "AGE -0.36\n",
      "B -0.27\n",
      "PTRATIO 0.18\n",
      "TAX -0.11\n",
      "DIS 0.1\n",
      "NOX 0.04\n",
      "CHAS -0.04\n",
      "ZN -0.01\n",
      "RAD 0.0\n",
      "INDUS 0.0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(instances)):\n",
    "    print \"Instance\", i\n",
    "    print \"Bias (trainset mean)\", biases[i]\n",
    "    print \"Feature contributions:\"\n",
    "    for c, feature in sorted(zip(contributions[i], \n",
    "                                 boston.feature_names), \n",
    "                             key=lambda x: -abs(x[0])):\n",
    "        print feature, round(c, 2)\n",
    "    print \"-\"*20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normalize': False, 'n_jobs': 1, 'rank_': 13, 'fit_intercept': True, '_residues': 11080.276284149873, 'coef_': array([ -1.07170557e-01,   4.63952195e-02,   2.08602395e-02,\n",
      "         2.68856140e+00,  -1.77957587e+01,   3.80475246e+00,\n",
      "         7.51061703e-04,  -1.47575880e+00,   3.05655038e-01,\n",
      "        -1.23293463e-02,  -9.53463555e-01,   9.39251272e-03,\n",
      "        -5.25466633e-01]), 'copy_X': True, 'intercept_': 36.491103280361038, 'singular_': array([  3.94958310e+03,   1.77662274e+03,   6.42864253e+02,\n",
      "         3.66980826e+02,   1.59116390e+02,   1.18692322e+02,\n",
      "         9.01718207e+01,   6.93889529e+01,   4.06572735e+01,\n",
      "         2.44223087e+01,   1.13502686e+01,   5.50918200e+00,\n",
      "         1.24178413e+00])}\n",
      "Multiple Linear Regression R-squared = 0.740607742865\n"
     ]
    }
   ],
   "source": [
    "#linear regression\n",
    "from sklearn.datasets import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = load_boston()\n",
    "model = LinearRegression()\n",
    "model.fit(data.data, data.target)\n",
    "print model.__dict__\n",
    "R2 = model.score(data.data, data.target) \n",
    "print \"Multiple Linear Regression R-squared = %s\" % R2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
